[{"authors":[],"categories":[],"content":"Summary.\n内容分析 使用特定的卷积核对一个图像进行卷积操作可以得到特定风格的图片，本题中使用的卷积核有, 边缘检测、高斯模糊、轮廓。调用读入图片的函数，对图像进行卷积操作，最后保存图片，即可完成图像转换。\n设计方法 图像读入和保存的函数已在 cv.c 中完成，只需要正确调用即可完图像输入输出操作。 所以，本题需要编写的主要部分就是卷积函数。\n调用图像读入函数后，可以得到返回的指向原图（一个 BMPImage 结构体变量）的指针，将这个指针和一个卷积核（二维数组）作为卷积函数的参数传入，返回一个指向新图像（也是一个 BMPImage 结构体变量）的指针，然后将这个指向新图像的指针传给图像保存函数，保存新图像到 bmp 文件中。这样就完成了本题\n所以，按照上面的分析，可以以下面的函数原型设计卷积函数：\nBMPImage* Convolution2D(BMPImage* img, const float kernel[3][3]); 在卷积函数内，使用卷积算法遍历每个像素点，就能很容易的得到转换后的图像的所有像素的数据\n算法分析 按照卷积算法设计卷积函数：\n我们先创建一个指向返回图像的指针，然后为返回的图像（新图像）分配内存\nBMPImage* convdImg = (BMPImage*)malloc(sizeof(BMPImage)); 由于转换后的图像与原图像的文件头信息头一致，只有各个像素点不同，所以直接用原图像的数据为新图像初始化\nmemcpy(convdImg, img, sizeof(*img)); convdImg-\u0026gt;imageData= (PixelBlock*)malloc(sizeof(PixelBlock)*(convdImg-\u0026gt;width)*(convdImg-\u0026gt;height)); 然后遍历每个像素点，用三个浮点变量 rr gg 和 bb 分别储存该像素点在 R、G、B 通道上的卷积结果。 完成每个像素点的卷积计算后就得到了转换后图像的各个像素的数据\n核心代码如下，详细逻辑见注释：\n// 九个方向 int const dx_[] = {-1, -1, -1, 0, 0, 0, 1, 1, 1}; int const dy_[] = {-1, 0, 1, -1, 0, 1, -1, 0, 1}; for (int i=0; i\u0026lt;convdImg-\u0026gt;height; i++) { for (int j=0; j\u0026lt;convdImg-\u0026gt;width; j++) { float rr=0, gg=0, bb=0; // 卷积后的rgb结果 // 创建一个空像素（rgb都为0） PixelBlock convolution_sum = {0,0,0}; // 卷积 for (int k=0; k\u0026lt;9; k++) { int const dx = dx_[k]; int const dy = dy_[k]; // 防止内存越界访问 if ( i+dx\u0026lt;0 || i+dx\u0026gt;=img-\u0026gt;height || j+dy\u0026lt;0 || j+dy\u0026gt;=img-\u0026gt;width ) { continue; } rr+=img-\u0026gt;imageData[(i+dx)*(img-\u0026gt;width)+j+dy].R * kernel[dx+1][dy+1]; gg+=img-\u0026gt;imageData[(i+dx)*(img-\u0026gt;width)+j+dy].G * kernel[dx+1][dy+1]; bb+=img-\u0026gt;imageData[(i+dx)*(img-\u0026gt;width)+j+dy].B * kernel[dx+1][dy+1]; } convolution_sum.B = bb; convolution_sum.G = gg; convolution_sum.R = rr; // 新图像得到像素值 convdImg-\u0026gt;imageData[i*(img-\u0026gt;width)+j] = convolution_sum; } } } 需要注意的是，卷积计算时需要判断是否存在内存越界访问（代码中的 if 语句） 最后返回指向新图像的指针即可\n部分卷积结果 ","date":"2024年3月23日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/blog/2024/03/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E4%BD%9C%E4%B8%9A%E8%AE%B0%E5%BD%95/","series":[],"smallImg":"","tags":[],"timestamp":1711179737,"title":"图像卷积作业记录"},{"authors":[],"categories":[],"content":"双指针、前缀和、差分算法.\n双指针 解释 快慢指针 左右指针 双指针是一种思想，一种技巧或一种方法，并不是什么特别具体的算法，在二分查找等算法中经常用到这个技巧。具体就是用两个变量动态存储两个或多个结点，来方便我们进行一些操作。通常用在线性的数据结构中，比如链表和数组，有时候也会用在图算法中。\n在我们遇到像数组，链表这类数据结构的算法题目的时候，应该要想得到双指针的套路来解决问题。特别是链表类的题目，经常需要用到两个或多个指针配合来记忆链表上的节点，完成某些操作。链表这种数据结构也是树形结构和图的原型，所以有时候在关于图和树形结构的算法题目中也会用到双指针。\n当你遇到此类数据结构，尝试使用双指针来解题的时候，可以从以下几个双指针类题目的套路入手进行思考\n快慢指针 类似于龟兔赛跑，两个链表上的指针从同一节点出发，其中一个指针前进速度是另一个指针的两倍。利用快慢指针可以用来解决某些算法问题，比如：\n计算链表的中点：快慢指针从头节点出发，每轮迭代中，快指针向前移动两个节点，慢指针向前移动一个节点，最终当快指针到达终点的时候，慢指针刚好在中间的节点。 判断链表是否有环：如果链表中存在环，则在链表上不断前进的指针会一直在环里绕圈子，且不能知道链表是否有环。使用快慢指针，当链表中存在环时，两个指针最终会在环中相遇。 判断链表中环的起点：当我们判断出链表中存在环，并且知道了两个指针相遇的节点，我们可以让其中任一个指针指向头节点，然后让它俩以相同速度前进，再次相遇时所在的节点位置就是环开始的位置。 求链表中环的长度：只要相遇后一个不动，另一个前进直到相遇算一下走了多少步就好了 求链表倒数第 k 个元素：先让其中一个指针向前走 k 步，接着两个指针以同样的速度一起向前进，直到前面的指针走到尽头了，则后面的指针即为倒数第 k 个元素。（严格来说应该叫先后指针而非快慢指针） 碰撞指针 一般都是排好序的数组或链表，否则无序的话这两个指针的位置也没有什么意义。特别注意两个指针的循环条件在循环体中的变化，小心右指针跑到左指针左边去了。常用来解决的问题有:\n二分查找问题 n 数之和问题：比如两数之和问题，先对数组排序然后左右指针找到满足条件的两个数。如果是三数问题就转化为一个数和另外两个数的两数问题。以此类推。 滑动窗口法 两个指针，一前一后组成滑动窗口，并计算滑动窗口中的元素的问题。这类问题一般包括：\n字符串匹配问题 子数组问题 例题 前缀和 解释 什么是前缀和？ 一维前缀和：\n有一个一维数组 $x$ 和该数组的一维前缀和数组 $y$ ，则 $x$ 和 $y$ 满足以下关系：\n$$y_n = \\sum_{i=1}^{n} x_n$$\n二维前缀和：\n![[Clip_2024-03-16_20-10-14.png]]\n前缀和公式 一维前缀和 公式： $y_n = y_{n-1} + x_n$\n代码如下：\nfor (int i=0; i\u0026lt;n; i++) { if (i == 0) y[i] = x[i]; else y[i] = y[i-1] + x[i]; } 二维前缀和 公式：\n$$b_{x,y} = b_{x-1,y} + b_{x,y-1} - b_{x-1, y-1} + a_{x,y}$$\n代码：\nfor (int x=0; x\u0026lt;n; x++) { for (int y=0; y\u0026lt;m; y++) { if (x==0 \u0026amp;\u0026amp; y==0) b[x][y] = a[x][y]; else if (x==0) b[x][y] = b[x][y-1] + a[x][y]; else if (y==0) b[x][y] = b[x-1][y] + a[x][y]; else b[x][y] = b[x-1][y] + b[x][y-1] - b[x-1][y-1] + a[x][y]; } } [!note] 前缀和有什么用？\n前缀和是一种预处理，用于降低查询时的时间复杂度。\n举个例子：给定 n 个整数，然后进行 m 次询问，每次询问求一个区间内值的和。\n如果用暴力写法，那每次询问都需要从区间左端点循环到区间右端点求和，时间复杂度较大。\n这种时候就可以预先求出该数组的一维前缀和。\n例题 P3131 [USACO16JAN] Subsequences Summing to Sevens S\n差分 解释 差分是前缀和的逆运算。若有前缀和数组 $A_n$，差分数组 $B_n$，则有：\n$$A_i = \\sum_{i=1}^{n} B_i$$\n[!tip] 差分数组与前缀和数组的关系 差分数组与前缀和数组是一一对应的，换句话说，已知其一可确定另一数组.\n例子： 已知某前缀和数组 $A_n$ ，现需要对该前缀和数组的 $[l, r]$ 索引处的值增加 $a$ .\n解决方法：暴力复杂度 O(n) -\u0026gt; O (1)\n求解差分数组 $B_n$（差分数组 $A_i = \\sum_{i=1}^{n} B_i$ ） 增加： $B_l = B_l + a$ 消除 $r$ 后的影响：$B_{r+1} = B_{r+1} - a$ ![[Clip_2024-03-16_21-44-34.png]]\n![[Clip_2024-03-16_21-56-58.png]]\n[!NOTE] 对于二维差分？ 容易验证，二维差分数组的某一点 $(x, y)$ 所影响的范围为其右下角所有点（包括该点）\n所以，画图易知，若要使二维前缀和数组 $A_n$ $(x_1, y_1)$ 到 $(x_2, y_2)$ 之间的所有点增加 $a$. 可以使 $A_n$ 对应的二维差分数组 $S_n$ 作以下变换： $$S[x_1, y_1] += a, S[x_2 + 1, y_1] -= a, S[x_1, y_2 + 1] -= a, S[x_2 + 1, y_2 + 1] += a$$ ![[Clip_2024-03-17_11-19-39 1.png]]\n例题 一维差分 1. P 3397 地毯\n[!INFO] 题意 在 n×n 的格子上有 m 个地毯。 给出这些地毯的信息，问每个点被多少个地毯覆盖。\n此题看似为二维，其实可以用一维差分解决，见代码：\n0 0 0 0 0 0 0 +1 0 0 0 -1 0 +1 0 0 0 -1 0 +1 0 0 0 -1 0 +1 0 0 0 -1 0 0 0 0 0 0 // P3397 地毯 // https://www.luogu.com.cn/problem/P3397 #include \u0026lt;bits/stdc++.h\u0026gt; #define int long long using namespace std; int n, m; int ori[1010][1010]; // 地毯数量（前缀和） int diff[1010][1010]; // 差分数组 signed main() { cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m; for (int i=0; i\u0026lt;m; i++) { int x1, y1, x2, y2; cin \u0026gt;\u0026gt; x1 \u0026gt;\u0026gt; y1 \u0026gt;\u0026gt; x2 \u0026gt;\u0026gt; y2; for (int j=x1-1; j\u0026lt;=x2-1; j++) diff[j][y1-1] ++; for (int j=x1-1; j\u0026lt;=x2-1; j++) diff[j][y2] --; } for (int i=0; i\u0026lt;n; i++) { for (int j=0; j\u0026lt;n; j++) { if (j==0) ori[i][j] = diff[i][j]; else ori[i][j] = ori[i][j-1] + diff[i][j]; cout \u0026lt;\u0026lt; ori[i][j] \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } cout \u0026lt;\u0026lt; endl; } return 0; } ","date":"2024年3月23日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/blog/2024/03/%E5%8F%8C%E6%8C%87%E9%92%88%E5%89%8D%E7%BC%80%E5%92%8C%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/","series":[{"title":"算法笔记","url":"/series/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"}],"smallImg":"","tags":[{"title":"双指针","url":"/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"},{"title":"前缀和","url":"/tags/%E5%89%8D%E7%BC%80%E5%92%8C/"},{"title":"差分","url":"/tags/%E5%B7%AE%E5%88%86/"},{"title":"算法","url":"/tags/%E7%AE%97%E6%B3%95/"},{"title":"笔记","url":"/tags/%E7%AC%94%E8%AE%B0/"}],"timestamp":1711163400,"title":"双指针、前缀和、差分算法"},{"authors":[],"categories":[],"content":"Welcome.\n","date":"2024年3月22日","img":"/news/2024/03/welcome/feature.png","lang":"zh-hans","langName":"简体中文","largeImg":"/news/2024/03/welcome/feature_hu4b4547b9c4fda6194c6ec6c997b8c6ab_17474359_500x0_resize_box_3.png","permalink":"/news/2024/03/welcome/","series":[{"title":"News","url":"/series/news/"}],"smallImg":"/news/2024/03/welcome/feature_hu4b4547b9c4fda6194c6ec6c997b8c6ab_17474359_180x0_resize_box_3.png","tags":[],"timestamp":1711115691,"title":"Welcome"},{"authors":[],"categories":[],"content":"本文为 PyTorch 学习笔记，介绍了 PyTorch 项目的基本代码范式。\n数据的导入 数据的导入需要用到两个 PyTorch 库，分别是 torch.utils.data.Dataset 和 torch.utils.data.DataLoader\nDataset 类的使用 可以使用 Dataset 类处理自定义的数据集，示例如下：\nclass MyDataset(Dataset): def __init__(self, root_dir, label_dir): self.root_dir = root_dir self.label_dir = label_dir self.path = os.path.join(self.root_dir, self.label_dir) self.image_name = os.listdir(self.path) def __getitem__(self, idx): img_name = self.image_name[idx] img_path = os.path.join(self.path, img_name) label = self.label_dir img = Image.open(img_path) return img, label def __len__(self): return len(self.image_name) 自定义自己的数据类需要继承 PyTorch 的 Dataset 类。\n方法的重写 继承 Dataset 父类后，还需要根据数据集的具体结构和任务需求重写一些方法，其中必须重写的方法包括：__init__ 、__getitem__、__len__\n构造方法的重写 重写构造方法的目的是定义其他方法所需的属性，例如上文示例中的根路径、标签路径等等。\ngetitem 方法的重写 除了对象 self 以外，__getitem__ 方法接受一个额外的变量 idx，表示数据集中一个数据的索引。\n我们需要重写该方法，根据传入的索引返回将要输入模型的特征和标签。\nlen 方法的重写 重写该方法以定义数据集的长度，例如上文示例用图片数量定义数据集长度\n使用已有数据集 这些提供的数据集使用方式很简单，只需要按照 PyTorch 文档中的使用方法填写参数，只需一行代码即可。\n例如 CIFAR10 的使用方法如下：\ntest_set = torchvision.datasets.CIFAR10( \u0026#34;./dataset\u0026#34;, train=False, transform=torchvision.transforms.ToTensor(), download=True ) 数据的处理 处理图片 PyTorch 在 torchvision.transforms 中提供了许多处理图片的工具，例如常用的工具类 torchvision.transforms.ToTensor() 用于将 PIL 或 ndarray (使用 opencv) 格式的图片转换为 PyTorch 的 Tensor 类型，以便输入模型。\n除此之外，transform 模块还提供了常见的图片处理工具，例如图片反转、切割等等。\nDataLoader 类的使用 test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=True, num_workers=0, drop_last=False) 遍历数据集的方法：\nfor data in test_loader: imgs, targets = data 搭建模型 搭建模型有两种方式，分别是：\n从零搭建 从已有的模型搭建 从零搭建模型 首先，定义一个继承 nn.module 的模型类，然后重写方法即可，示例如下：\nclass Model(nn.Module): def __init__(self): super(Model, self).__init__() self.model = nn.Sequential( nn.Conv2d(3, 32, 5, 1, 2), nn.MaxPool2d(2), nn.LeakyReLU(), nn.Conv2d(32, 32, 5, 1, 2), nn.MaxPool2d(2), nn.LeakyReLU(), nn.Conv2d(32, 64, 5, 1, 2), nn.MaxPool2d(2), nn.LeakyReLU(), nn.Flatten(), nn.Linear(64 * 4 * 4, 256), nn.ReLU(), nn.Linear(256, 64), nn.ReLU(), nn.Linear(64, 10), ) def forward(self, x): x = self.model(x) return x 从已有的模型搭建模型 导入已有模型 获取已有的模型有两种方式，第一种方式是使用 PyTorch 提供的知名模型，例如 vgg16。\nvgg16_pt = torchvision.models.vgg16(pretrained=True) 参数 pretrained 为 True 时会下载预训练后的模型参数，反之则使用未训练的随机模型参数\n修改已有模型 有时候，下载的模型无法满足我们的任务需求，例如处理分类问题时，模型的输出层的神经元个数与我们需要区分的类别数量不同。这个时候，我们就需要修改模型。\n修改模型所用到的函数或方法主要有以下几个：\n# 1. 增加：add_module 方法，可以增加单层也可以增加 Sequential vgg16.add_module(\u0026#34;mod\u0026#34;, nn.Sequential(OrderedDict([ # 可以不给每层取名 (\u0026#34;linear\u0026#34;, nn.Linear(1000, 256)), (\u0026#34;relu\u0026#34;, nn.ReLU()), (\u0026#34;softmax\u0026#34;, nn.Softmax(10)) ]))) vgg16.add_module(nn.Linear(64, 10)) # 2. 修改：直接使用 [idx] 和 `.` print(vgg16) # 先print查看模型结构 vgg16.classifier[6] = nn.Linear(64, 10) vgg16.classifier[6] = nn.Sequential( nn.Linear(64, 10), nn.Linear(10, 5) ) # 3. 删除：使用 del 即可 del vgg16.classifier 训练模型 下面提供一个训练示例：\n# * 3. Create the model object and Setting hyperparameters # create model object model = Model() if torch.cuda.is_available(): model = model.cuda() # define the loss function loss_fn = nn.CrossEntropyLoss() if torch.cuda.is_available(): loss_fn = loss_fn.cuda() # define the optimizer learning_rate = 0.01 optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # optimizer = torch.optim.Adam(model.parameters()) # Setting total_train_step = 0 total_test_step = 0 epoch = 30 # set tensorboard writer = SummaryWriter(\u0026#34;./logs_model\u0026#34;) # * 4. Training the model for i in range(epoch): print(f\u0026#34;------ Epoch {i} begin. ------\u0026#34;) start_time = time.time() # train model.train() # for some certain layer(such as dropout), See PyTorch.org. for data in train_dataloader: imgs, targets = data # move to gpu if torch.cuda.is_available(): imgs, targets = imgs.cuda(), targets.cuda() output = model(imgs) loss = loss_fn(output, targets) # optimize optimizer.zero_grad() loss.backward() optimizer.step() total_train_step = total_train_step + 1 if total_train_step % 100 == 0: print(f\u0026#34;Train step: {total_train_step} / Loss: {loss}\u0026#34;) end_time = time.time() print(f\u0026#34;tic {end_time-start_time}\u0026#34;) writer.add_scalar(\u0026#34;train_loss(step)\u0026#34;, loss, total_train_step) # test model.eval() # for some certain layer total_test_loss = 0 total_accuracy = 0 with torch.no_grad(): for data in test_dataloader: imgs, targets = data # move to gpu if torch.cuda.is_available(): imgs, targets = imgs.cuda(), targets.cuda() output = model(imgs) # compute accuracy accuracy = (output.argmax(1) == targets).sum() total_accuracy += accuracy loss = loss_fn(output, targets) total_test_loss += loss # Show and log test info print(ColorText.info(f\u0026#34;\\nTotal loss in test set: {total_test_loss}\u0026#34;)) print( ColorText.info(f\u0026#34;Total accuracy in test set: {total_accuracy / test_set_size}\u0026#34;) ) writer.add_scalar(\u0026#34;test_loss(epoch)\u0026#34;, total_test_loss, total_test_step) writer.add_scalar( \u0026#34;test_accuracy(epoch)\u0026#34;, total_accuracy / test_set_size, total_test_step ) total_test_step += 1 # Save Model torch.save(model, f\u0026#34;model_{i}.pt\u0026#34;) print(ColorText.info(f\u0026#34;..::Model {i} Saved..\u0026#34;)) writer.close() 附录 Tensorboard 的使用 示例：\n首先在脚本内记录数据到指定路径\nfrom torch.urils.tensorboard import SummaryWriter # writer 对象 writer = SummaryWriter(\u0026#34;./logs\u0026#34;) # log_dir # 记录数据 writer.add_scalar(\u0026#34;loss curve\u0026#34;, y_value, x_value) # writer.close() 然后，命令行用 Tensorboard 打开日志路径\ntensorboard --log_dir ./logs ","date":"2024年3月22日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/blog/2024/03/pytorch/","series":[],"smallImg":"","tags":[{"title":"深度学习","url":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"title":"PyTorch","url":"/tags/pytorch/"}],"timestamp":1711112701,"title":"PyTorch"},{"authors":[],"categories":[],"content":"W.I.P 动态规划学习笔记.\n动态规划的演进 Dfs -\u0026gt; 记忆化搜索 -\u0026gt; 动态规划 (倒序递推/逆序递推 -\u0026gt; 空间优化)\n实现记忆化搜索，dfs 函数的参数应当尽量少，不影响边界的参数不要添加。 想要剪枝，一般多用参数\n动态规划 什么是动态规划 动态规划（英语：Dynamic programming，简称 DP），是一种在数学、管理科学、计算机科学、经济学和生物信息学中使用的，通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法。 动态规划常常适用于有重叠子问题和最优子结构性质的问题。\n动态规划的核心思想： 动态规划最核心的思想，就在于拆分子问题，记住过往，减少重复计算。\n示例： 下题\n// P1359 租用游艇 // https://www.luogu.com.cn/problem/P1359 #include \u0026lt;bits/stdc++.h\u0026gt; #define int long long using namespace std; const int N = 1000200; int timee[210][210]; // 直接从 i 到 j 的时间 int n; int mintime[210][210]; // 子问题分解，记录从 i 到 j 的最短时间 signed main(void) { cin \u0026gt;\u0026gt; n; for (int i=1; i\u0026lt;=n; i++) { for (int j=i+1; j\u0026lt;=n; j++) { cin \u0026gt;\u0026gt; timee[i][j]; } } // input part for (int i=1; i\u0026lt;=n; i++) { // 递推，从 1 到 i 的最短时间 -\u0026gt; 从 1 到 n 的最短时间 for (int j=i; j\u0026gt;=1; j--) { // 最后一步 if (j == i) mintime[1][i] = timee[1][i]; //！注意 else mintime[1][i] = min(mintime[1][i], timee[j][i] + mintime[1][j]); } } cout \u0026lt;\u0026lt; mintime[1][n]; return 0; } ","date":"2024年3月22日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/blog/2024/03/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","series":[],"smallImg":"","tags":[{"title":"算法，动态规划","url":"/tags/%E7%AE%97%E6%B3%95%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}],"timestamp":1711112641,"title":"动态规划"},{"authors":[],"categories":[],"content":"本文为搜索算法学习笔记。\n深度优先搜索（DFS） 深度优先搜索的步骤分为 1.递归下去 2.回溯上来。 顾名思义，深度优先，则是以深度为准则，先一条路走到底，直到达到目标。这里称之为递归下去。否则既没有达到目标又无路可走了，那么则退回到上一步的状态，走其他路。这便是回溯上来。\n把正整数 $n$ 分解为 $3$ 个不同的正整数，如 $6=1+2+3$，排在后面的数必须大于等于前面的数，输出所有方案\n原理：\nint m, arr[103]; // 决策需要参数 n：剩下的数 i:决策层数 a:上层决策结果 void dfs(int n, int i, int a) { if (n==0) { //输出，边界条件 for (int j = 0; j \u0026lt;= i; j++) printf(\u0026#34;%d \u0026#34;, arr[j]); printf(\u0026#34;\\n\u0026#34;); } if (i\u0026lt;=m) { for (int j = a; j \u0026lt;= n; j++) { arr[i] = j; // 存下当前决策 dfs(n - j, i + 1, j); // 下一层决策 } } } 代码：Luogu P1706 全排列问题\n#include \u0026lt;iomanip\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace std; int n; bool vis[50]; // 访问标记数组 int a[50]; // 排列数组，按顺序储存当前搜索结果 void dfs(int step) { if (step == n + 1) { // 边界 for (int i = 1; i \u0026lt;= n; i++) { cout \u0026lt;\u0026lt; setw(5) \u0026lt;\u0026lt; a[i]; // 保留5个场宽 } cout \u0026lt;\u0026lt; endl; return; } for (int i = 1; i \u0026lt;= n; i++) { if (vis[i] == 0) { // 判断数字i是否在正在进行的全排列中 vis[i] = 1; a[step] = i; dfs(step + 1); vis[i] = 0; // 这一步不使用该数 置0后允许下一步使用 } } return; } int main() { cin \u0026gt;\u0026gt; n; dfs(1); return 0; } 关于状态回溯等 TIPS [!状态回溯]\n在进行每一层决策时，要遍历当前层所有的情况。我们通常选定当前的决策，然后根据这一层的决策进行下一层决策（也就是开启下一层 dps）。然后先清除之前的决策，再接着遍历当前层的其他\n例子 1：两种选择 -\u0026gt; 直接依次决策 kkksc03考前临时抱佛脚\nvoid dps(int i, int s_type) { if (i \u0026gt; s[s_type]) { min_sub = min ( min_sub, max(left0, right0) ); return; }\tleft0 += time0[s_type][i]; //先决策左脑 dps( i + 1, s_type); //依据当前层决策左脑的决策， 继续 dps left0 -= time0[s_type][i]; //清楚当前层决策 right0 += time0[s_type][i]; //决策右脑 dps( i + 1, s_type); right0 -= time0[s_type][i]; } 例子 2：n 种选择 -\u0026gt; 循环决策 [USACO1.5] 八皇后 Checker Challenge\nvoid queen(int i) { if (i \u0026gt;= n+1) { print(); return; } else { for (int k=1; k\u0026lt;=n; k++) // 循环 { if (b[k]==0 \u0026amp;\u0026amp; c[i+k]==0 \u0026amp;\u0026amp; d[i-k+n]==0) { a[i] = k; b[k] = 1; c[i+k] = 1; d[i-k + n] = 1; queen(i + 1); // dps b[k] = 0; // 清除 c[i+k] = 0; d[i-k + n] = 0; } } } } 例题 自然数的拆分问题\nint a[10001]={1},n; void search(int tot, int i) { if (tot == 0 \u0026amp;\u0026amp; i != 2) { //不能只输出一个数 int k; for (k=1; k\u0026lt;=i - 2; k++) { cout\u0026lt;\u0026lt;a[k]\u0026lt;\u0026lt;\u0026#34;+\u0026#34;; } cout\u0026lt;\u0026lt;a[k]\u0026lt;\u0026lt;endl; // i-1 return; } else { for (int j=a[i-1]; j\u0026lt;=tot; j++) //大于等于前一个数 { if (i\u0026lt;=n) // 拆分数不能比n大 { a[i] = j; search(tot - j, i + 1); // a[i] = 1; } } } } int main() { cin\u0026gt;\u0026gt;n; search(n,1); return 0; } 广度优先搜索（BFS） W.I.P\n","date":"2024年3月22日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/blog/2024/03/%E6%90%9C%E7%B4%A2/","series":[],"smallImg":"","tags":[],"timestamp":1711112641,"title":"搜索"},{"authors":[],"categories":[],"content":"Hi there, I\u0026rsquo;m SymmFz.\nWelcome to my blog.\n","date":"2024年3月22日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/about/","series":[],"smallImg":"","tags":[],"timestamp":1711065600,"title":"关于我"},{"authors":[],"categories":[],"content":"","date":"1年1月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/offline/","series":[],"smallImg":"","tags":[],"timestamp":-62135596800,"title":"Offline"},{"authors":[],"categories":[],"content":"","date":"1年1月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/contact/","series":[],"smallImg":"","tags":[],"timestamp":-62135596800,"title":"联系我们"}]
